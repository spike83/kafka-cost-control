=== Kubernetes

You can find all the deployment files in the link:../../deployment[deployment] folder. This folder use link:https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/[Kustomize] to simplify the deployment of multiple instances with some variations.

==== Create namespace

Create a namespace for the application

[,shell]
----
kubectl create namespace kafka-cost-control
----

==== Kafka metric scrapper

This part will be responsible to scrape kafka for relevant metrics. You will have to deploy one scrapper per kafka cluster. Depending on what metrics you want to provide you will need a user with read access to kafka metric but also kafka admin client. Read permission is enough ! You don't need a user with write permission.

This documentation will assume that you use the `dev/` folder, but you can configure as much Kustomize folders as you want.

Copy the environment sample file:
[,shell]
----
cd deployment/kafka-metric-scrapper/dev
cp .env.sample .env
vi .env
----
Edit the environment file with the correct output topic, endpoints and credentials.

Be sure to edit the *namespace* in the link:../../deployment/kafka-metric-scrapper/dev/kustomization.yaml[kustomization.yaml] file.

Deploy the dev environment using kubectl

[,shell]
----
cd /deployment/kafka-metric-scrapper
kubectl apply -k dev
----

Wait for the deployment to finish and check the output topic for metrics. You should receive new data every minute.

==== Kafka cost control

For this part we will deploy the kafka stream application that is responsible to enrich the metrics, TimescaleDB for storing the metrics, kafka connect instance to sink the metric into the database, a grafana dashboard and a simple UI to define prices and contexts.

This documentation will assume that you use the `dev/` folder, but you can configure as much Kustomize folders as you want.


Copy the environment sample file:
[,shell]
----
cd deployment/kafka-cost-control/dev
cp .env.sample .env
vi .env
----
Edit the environment file with the correct credentials. The database password can be randomly generated. It will be used by kafka connect and grafana.

Be sure to edit the *namespace* in the link:../../deployment/kafka-cost-control/dev/kustomization.yaml[kustomization.yaml] file.

You also may want to adapt the ingress files to use a proper hosts. You will need two hosts, one for grafana and one for the kafka cost control application.

Deploy the application using kubectl

[,shell]
----
cd /deployment/kafka-metric-scrapper
kubectl apply -k dev
----



